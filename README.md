# project

https://4b27n61r-8011.asse.devtunnels.ms/#/
rs mistral

Project Overview:

- **3 weeks plan**: Initiate with Qwen 3 coder on MOE, focusing on pruning to optimize for 3 DGX Sparks.
- **Hybrid LLM Provider**: Develop a system that switches between local GPU and cloud (DGX Sparks) based on task efficiency.
- **AI Coding Document**: Create a charter and plan, summarizing it in meetings with clear notes and documents.
- **Infrastructure**: Incorporate Aviary's infrastructure to support both coding and inference projects, ensuring seamless overlap.
- **Task Management**: Utilize APIs and SDKs for managing project tasks and binaries, leveraging reusable models and templates from the Aviary team.
- **Efficiency Focus**: Prioritize GPT-oss for certain tasks due to faster performance despite Qwen's larger parameter size.
- **Collaboration**: Ensure all team members (7 in coding, others in ideation) work cohesively towards common goals.
- **Router System**: Design an inference router that dynamically routes tasks to the best resource, whether local or cloud-based.
- **Documentation**: Maintain clear and concise documentation throughout the project to ensure understanding and continuity.
- **Reusable Resources**: Aim to create reusable model binaries and infrastructure templates to enhance project scalability and efficiency.
- multiple md docs

https://github.com/continuedev/continue

https://github.com/cline/cline
ppt

https://huggingface.co/models?pipeline_tag=text-generation&num_parameters=min:9B&sort=trending&search=code
#anything starting from 9b or ~30b should be details and can start off as base models

https://www.continue.dev/

https://github.com/continuedev/continue

https://github.com/cline/linear-mcp

https://github.com/cline/mcp-marketplace

https://github.com/microsoft/vscode-copilot-chat

